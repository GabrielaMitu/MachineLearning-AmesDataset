{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a regression model for predicting house sale prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Insper\\8-Semestre\\MachineLearning\\MachineLearning-AmesDataset\\data\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = pathlib.Path.cwd().parent / 'data'\n",
    "print(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data_path = DATA_DIR / 'processed' / 'ames_clean.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(clean_data_path, 'rb') as file:\n",
    "    data = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2877 entries, 0 to 2929\n",
      "Data columns (total 70 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   MS.SubClass      2877 non-null   category\n",
      " 1   MS.Zoning        2877 non-null   category\n",
      " 2   Lot.Frontage     2877 non-null   float64 \n",
      " 3   Lot.Area         2877 non-null   float64 \n",
      " 4   Lot.Shape        2877 non-null   category\n",
      " 5   Land.Contour     2877 non-null   category\n",
      " 6   Lot.Config       2877 non-null   category\n",
      " 7   Land.Slope       2877 non-null   category\n",
      " 8   Neighborhood     2877 non-null   category\n",
      " 9   Bldg.Type        2877 non-null   category\n",
      " 10  House.Style      2877 non-null   category\n",
      " 11  Overall.Qual     2877 non-null   category\n",
      " 12  Overall.Cond     2877 non-null   category\n",
      " 13  Roof.Style       2877 non-null   category\n",
      " 14  Mas.Vnr.Type     2877 non-null   category\n",
      " 15  Mas.Vnr.Area     2877 non-null   float64 \n",
      " 16  Exter.Qual       2877 non-null   category\n",
      " 17  Exter.Cond       2877 non-null   category\n",
      " 18  Foundation       2877 non-null   category\n",
      " 19  Bsmt.Qual        2877 non-null   category\n",
      " 20  Bsmt.Cond        2877 non-null   category\n",
      " 21  Bsmt.Exposure    2877 non-null   category\n",
      " 22  BsmtFin.Type.1   2877 non-null   category\n",
      " 23  BsmtFin.SF.1     2877 non-null   float64 \n",
      " 24  BsmtFin.Type.2   2877 non-null   category\n",
      " 25  BsmtFin.SF.2     2877 non-null   float64 \n",
      " 26  Bsmt.Unf.SF      2877 non-null   float64 \n",
      " 27  Total.Bsmt.SF    2877 non-null   float64 \n",
      " 28  Heating.QC       2877 non-null   category\n",
      " 29  Central.Air      2877 non-null   category\n",
      " 30  Electrical       2877 non-null   category\n",
      " 31  X1st.Flr.SF      2877 non-null   float64 \n",
      " 32  X2nd.Flr.SF      2877 non-null   float64 \n",
      " 33  Low.Qual.Fin.SF  2877 non-null   float64 \n",
      " 34  Gr.Liv.Area      2877 non-null   float64 \n",
      " 35  Bsmt.Full.Bath   2877 non-null   float64 \n",
      " 36  Bsmt.Half.Bath   2877 non-null   float64 \n",
      " 37  Full.Bath        2877 non-null   float64 \n",
      " 38  Half.Bath        2877 non-null   float64 \n",
      " 39  Bedroom.AbvGr    2877 non-null   float64 \n",
      " 40  Kitchen.AbvGr    2877 non-null   float64 \n",
      " 41  Kitchen.Qual     2877 non-null   category\n",
      " 42  TotRms.AbvGrd    2877 non-null   float64 \n",
      " 43  Functional       2877 non-null   category\n",
      " 44  Fireplaces       2877 non-null   float64 \n",
      " 45  Garage.Type      2877 non-null   category\n",
      " 46  Garage.Finish    2877 non-null   category\n",
      " 47  Garage.Cars      2877 non-null   float64 \n",
      " 48  Garage.Area      2877 non-null   float64 \n",
      " 49  Paved.Drive      2877 non-null   category\n",
      " 50  Wood.Deck.SF     2877 non-null   float64 \n",
      " 51  Open.Porch.SF    2877 non-null   float64 \n",
      " 52  Enclosed.Porch   2877 non-null   float64 \n",
      " 53  X3Ssn.Porch      2877 non-null   float64 \n",
      " 54  Screen.Porch     2877 non-null   float64 \n",
      " 55  Pool.Area        2877 non-null   float64 \n",
      " 56  Fence            2877 non-null   category\n",
      " 57  Misc.Val         2877 non-null   float64 \n",
      " 58  Mo.Sold          2877 non-null   float64 \n",
      " 59  Yr.Sold          2877 non-null   float64 \n",
      " 60  Sale.Type        2877 non-null   category\n",
      " 61  Sale.Condition   2877 non-null   category\n",
      " 62  SalePrice        2877 non-null   float64 \n",
      " 63  Condition        2877 non-null   category\n",
      " 64  HasShed          2877 non-null   bool    \n",
      " 65  HasAlley         2877 non-null   bool    \n",
      " 66  Exterior         2877 non-null   category\n",
      " 67  Garage.Age       2877 non-null   float64 \n",
      " 68  Remod.Age        2877 non-null   float64 \n",
      " 69  House.Age        2877 non-null   float64 \n",
      "dtypes: bool(2), category(34), float64(34)\n",
      "memory usage: 889.4 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = data.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data for the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data all cleaned, and all the missing values accounted for, lets focus on transforming the data for the model.\n",
    "\n",
    "Lets remember what a model is. \n",
    "\n",
    "- A predictive model is a **set** of functions that receive data as input and produce a prediction, that is, an estimate of the target value as output.\n",
    "- **Train** a model is to search the set of candidate functions for one that adequately represents the **training dataset**.\n",
    "- The adequacy of a candidate function to the training data is usually determined by a **loss function** that measures how well the predictions of the function match the real values of the target within the training dataset. It is common to define a *loss function per data item* (e.g. absolute error, quadratic error, etc) and to construct the *loss function over the dataset* as the *average prediction loss*.\n",
    "\n",
    "Many models are **parametric models**. In this case, each function of the set of functions that makes the model is constructed from a vector of **parameters** that define the function, forming a **parametric function**. For instance: the linear model constructs prediction values out of a linear combination of the input features, plus a constant. The weights of the linear combination plus the constant are the parameters of the model. The set of functions that can be represented by this model is given by all possible values of the vector of parameters that define the function.\n",
    "\n",
    "Some models are called **non-parametric models**. These models usually do not have a parametric form (like the linear model). But the terminology is a bit misleading, though: usually these models *do* have parameters, and potentially an open-ended set of them! For instance, consider the \"decision tree\" model, which is one of the most prominent models of this category. The decision tree may not have a formula for the predicted value, but it does have parameters, many of them: each decision in the tree involves a choice of feature and a threshold level, and those choices must be stored as parameters of the model for use in future predictions.\n",
    "\n",
    "Each model has specific requirements for the format of the input data. Most of the time, the minimum requirement is that:\n",
    "\n",
    "- All columns are numeric;\n",
    "- There are no missing values.\n",
    "\n",
    "Some models have extra requirements. For example: the support-vector-machines model requires that the input features have comparable standard deviations - having features that have large discrepancies between features in terms of their order of magnitude (such as a feature in the fractions of unit range and another in the tens of thousands) will result in poor prediction quality.\n",
    "\n",
    "And some models may not have any special requirement at all. We will study each of those in detail in this course.\n",
    "\n",
    "Lets start our study with a simple model: the *multivariate linear regression* model. This is a model that presents the minimum requirements listed above. So we need to do a bit of processing on the original features:\n",
    "\n",
    "- *Numerical features* stay as given;\n",
    "- *Categorical features* have to be transformed into numerical features. In order to do so we need to **encode** these features, that is: to transform them into new features that convey the same information, but in a numerical form, and in a way that \"makes sense\" - we'll see it below.\n",
    "- *Ordinal features* can be transformed into numerical features in the same way as the caegorical features, or could be assigned increasing numbers in conformity with the ordered nature of the categories of the feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets identify all categorical variables - both nominal (that is, categoricals without category order) and ordinal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = []\n",
    "ordinal_columns = []\n",
    "for col in model_data.select_dtypes('category').columns:\n",
    "    if model_data[col].cat.ordered:\n",
    "        ordinal_columns.append(col)\n",
    "    else:\n",
    "        categorical_columns.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lot.Shape',\n",
       " 'Land.Slope',\n",
       " 'Overall.Qual',\n",
       " 'Overall.Cond',\n",
       " 'Exter.Qual',\n",
       " 'Exter.Cond',\n",
       " 'Heating.QC',\n",
       " 'Electrical',\n",
       " 'Kitchen.Qual',\n",
       " 'Functional',\n",
       " 'Paved.Drive',\n",
       " 'Fence']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordinal_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MS.SubClass',\n",
       " 'MS.Zoning',\n",
       " 'Land.Contour',\n",
       " 'Lot.Config',\n",
       " 'Neighborhood',\n",
       " 'Bldg.Type',\n",
       " 'House.Style',\n",
       " 'Roof.Style',\n",
       " 'Mas.Vnr.Type',\n",
       " 'Foundation',\n",
       " 'Bsmt.Qual',\n",
       " 'Bsmt.Cond',\n",
       " 'Bsmt.Exposure',\n",
       " 'BsmtFin.Type.1',\n",
       " 'BsmtFin.Type.2',\n",
       " 'Central.Air',\n",
       " 'Garage.Type',\n",
       " 'Garage.Finish',\n",
       " 'Sale.Type',\n",
       " 'Sale.Condition',\n",
       " 'Condition',\n",
       " 'Exterior']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding ordinal variables "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal variables can be transformed into integer numbers in a straightforward manner: the lowest category is assigned the value \"zero\", the next category is given the value \"one\", etc. The `Pandas` library has a function for this task: `factorize()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ordinal_columns:\n",
    "    codes, _ = pd.factorize(data[col], sort=True)\n",
    "    model_data[col] = codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets confirm that the variables are no longer ordinal, but now are integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2877 entries, 0 to 2929\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype\n",
      "---  ------        --------------  -----\n",
      " 0   Lot.Shape     2877 non-null   int64\n",
      " 1   Land.Slope    2877 non-null   int64\n",
      " 2   Overall.Qual  2877 non-null   int64\n",
      " 3   Overall.Cond  2877 non-null   int64\n",
      " 4   Exter.Qual    2877 non-null   int64\n",
      " 5   Exter.Cond    2877 non-null   int64\n",
      " 6   Heating.QC    2877 non-null   int64\n",
      " 7   Electrical    2877 non-null   int64\n",
      " 8   Kitchen.Qual  2877 non-null   int64\n",
      " 9   Functional    2877 non-null   int64\n",
      " 10  Paved.Drive   2877 non-null   int64\n",
      " 11  Fence         2877 non-null   int64\n",
      "dtypes: int64(12)\n",
      "memory usage: 292.2 KB\n"
     ]
    }
   ],
   "source": [
    "model_data[ordinal_columns].info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the original values with the encoded values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lot.Shape\n",
       "Reg    1825\n",
       "IR1     960\n",
       "IR2      76\n",
       "IR3      16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Lot.Shape'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lot.Shape\n",
       "0    1825\n",
       "1     960\n",
       "2      76\n",
       "3      16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['Lot.Shape'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding nominal variables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With nominal variables there is no notion of order among categories. Therefore, it would be a conceptual mistake to encode them in the same manner as the ordinal variables. For instance, consider the `Exterior` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exterior\n",
       "VinylSd    1024\n",
       "HdBoard     439\n",
       "MetalSd     432\n",
       "Wd Sdng     401\n",
       "Plywood     218\n",
       "CemntBd     126\n",
       "BrkFace      86\n",
       "WdShing      55\n",
       "Stucco       42\n",
       "AsbShng      41\n",
       "Other        13\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data['Exterior'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We cannot assign an order here, lest we end up with equations like `HdBoard` + `Plywood` = `CemntBd`, which are nonsense. \n",
    "\n",
    "The strategy here to encode `Exterior` is to create several new numerical variables to represent the membership of a given data item to one of the `Exterior` categories. These are called **dummy variables**. Each of these new variables contain only the values \"zero\" or \"one\" (i.e. they are binary variables), where $1$ denotes that the data item belongs to the category represented by the variable. Evidently, for a given data item, only one dummy variable has a value of $1$, all remaining are $0$.\n",
    "\n",
    "There are two types of dummy variable encoding:\n",
    "\n",
    "- \"One-hot\" encoding: in this case we create one dummy variable per category. Let's look at the `Exterior` feature as an example. The `Pandas` function `get_dummies()` can do the encoding for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AsbShng</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BrkFace</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CemntBd</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HdBoard</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetalSd</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plywood</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stucco</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VinylSd</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wd Sdng</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WdShing</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior</th>\n",
       "      <td>BrkFace</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>VinylSd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        1        2        3        4\n",
       "AsbShng     False    False    False    False    False\n",
       "BrkFace      True    False    False     True    False\n",
       "CemntBd     False    False    False    False    False\n",
       "HdBoard     False    False    False    False    False\n",
       "MetalSd     False    False    False    False    False\n",
       "Plywood     False    False    False    False    False\n",
       "Stucco      False    False    False    False    False\n",
       "VinylSd     False     True    False    False     True\n",
       "Wd Sdng     False    False     True    False    False\n",
       "WdShing     False    False    False    False    False\n",
       "Other       False    False    False    False    False\n",
       "Exterior  BrkFace  VinylSd  Wd Sdng  BrkFace  VinylSd"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = model_data['Exterior']\n",
    "encoded_data = pd.get_dummies(original_data)\n",
    "\n",
    "aux_dataframe = encoded_data\n",
    "aux_dataframe['Exterior'] = original_data.copy()\n",
    "\n",
    "aux_dataframe.head().transpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that for each value of `Exterior`, only the corresponding dummy is flagged.\n",
    "\n",
    "One-hot encoding is a popular technique in Machine Learning. Statisticians, however, prefer a slightly different way of dummy encoding which is:\n",
    "\n",
    "- Choose a category to *not encode* (this is called the *base category*)\n",
    "- Generate dummies for the remaining categories. That is:\n",
    "    - If the data item belongs to the base category, no dummy receives a value of $1$;\n",
    "    - Otherwise, set the corresponding dummy to $1$.\n",
    "\n",
    "The same `get_dummies()` function of `Pandas` can do this automatically with the `drop_first` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BrkFace</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CemntBd</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HdBoard</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MetalSd</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plywood</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stucco</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VinylSd</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wd Sdng</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WdShing</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exterior</th>\n",
       "      <td>BrkFace</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>Wd Sdng</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>VinylSd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0        1        2        3        4\n",
       "BrkFace      True    False    False     True    False\n",
       "CemntBd     False    False    False    False    False\n",
       "HdBoard     False    False    False    False    False\n",
       "MetalSd     False    False    False    False    False\n",
       "Plywood     False    False    False    False    False\n",
       "Stucco      False    False    False    False    False\n",
       "VinylSd     False     True    False    False     True\n",
       "Wd Sdng     False    False     True    False    False\n",
       "WdShing     False    False    False    False    False\n",
       "Other       False    False    False    False    False\n",
       "Exterior  BrkFace  VinylSd  Wd Sdng  BrkFace  VinylSd"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data = model_data['Exterior']\n",
    "encoded_data = pd.get_dummies(original_data, drop_first=True)\n",
    "\n",
    "aux_dataframe = encoded_data\n",
    "aux_dataframe['Exterior'] = original_data.copy()\n",
    "\n",
    "aux_dataframe.head().transpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we are now missing the dummy variable for the `AsbShng` category.\n",
    "\n",
    "Why to encode things this way? If we don't drop one of the dummies, then it will always be the case that the sum of the values of the dummies is $1$ (since each data item must belong to one of the categories). The linear model, particularly very popular with the statisticians, implies the existence of a fictitious feature containing, for all data items, the value $1$. Hence we end up having a set of variables where a linear combination of them (in this case, the sum of the dummies) matches the value at another variable. This has numerical computing implications for the linear model, that we will discuss in class.\n",
    "\n",
    "Since we want to use the linear model in this notebook, lets encode all categoricals with the `drop_first` alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.get_dummies(model_data, drop_first=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our dataset has a lot more variables!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2877 entries, 0 to 2929\n",
      "Columns: 165 entries, Lot.Frontage to Exterior_Other\n",
      "dtypes: bool(119), float64(34), int64(12)\n",
      "memory usage: 1.4 MB\n"
     ]
    }
   ],
   "source": [
    "model_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From column \"MS.SubClass\" we made \"MS.SubClass_30\", \"MS.SubClass_50\", \"MS.SubClass_60\", \"MS.SubClass_70\", \"MS.SubClass_80\", \"MS.SubClass_85\", \"MS.SubClass_90\", \"MS.SubClass_120\", \"MS.SubClass_160\", \"MS.SubClass_190\", \"MS.SubClass_Other\"\n",
      "\n",
      "From column \"MS.Zoning\" we made \"MS.Zoning_RH\", \"MS.Zoning_RL\", \"MS.Zoning_RM\"\n",
      "\n",
      "From column \"Land.Contour\" we made \"Land.Contour_HLS\", \"Land.Contour_Low\", \"Land.Contour_Lvl\"\n",
      "\n",
      "From column \"Lot.Config\" we made \"Lot.Config_CulDSac\", \"Lot.Config_FR2\", \"Lot.Config_FR3\", \"Lot.Config_Inside\"\n",
      "\n",
      "From column \"Neighborhood\" we made \"Neighborhood_BrDale\", \"Neighborhood_BrkSide\", \"Neighborhood_ClearCr\", \"Neighborhood_CollgCr\", \"Neighborhood_Crawfor\", \"Neighborhood_Edwards\", \"Neighborhood_Gilbert\", \"Neighborhood_IDOTRR\", \"Neighborhood_MeadowV\", \"Neighborhood_Mitchel\", \"Neighborhood_NAmes\", \"Neighborhood_NPkVill\", \"Neighborhood_NWAmes\", \"Neighborhood_NoRidge\", \"Neighborhood_NridgHt\", \"Neighborhood_OldTown\", \"Neighborhood_SWISU\", \"Neighborhood_Sawyer\", \"Neighborhood_SawyerW\", \"Neighborhood_Somerst\", \"Neighborhood_StoneBr\", \"Neighborhood_Timber\", \"Neighborhood_Veenker\"\n",
      "\n",
      "From column \"Bldg.Type\" we made \"Bldg.Type_2fmCon\", \"Bldg.Type_Duplex\", \"Bldg.Type_Twnhs\", \"Bldg.Type_TwnhsE\"\n",
      "\n",
      "From column \"House.Style\" we made \"House.Style_1.5Unf\", \"House.Style_1Story\", \"House.Style_2.5Fin\", \"House.Style_2.5Unf\", \"House.Style_2Story\", \"House.Style_SFoyer\", \"House.Style_SLvl\"\n",
      "\n",
      "From column \"Roof.Style\" we made \"Roof.Style_Hip\", \"Roof.Style_Other\"\n",
      "\n",
      "From column \"Mas.Vnr.Type\" we made \"Mas.Vnr.Type_Stone\", \"Mas.Vnr.Type_Other\", \"Mas.Vnr.Type_None\"\n",
      "\n",
      "From column \"Foundation\" we made \"Foundation_CBlock\", \"Foundation_PConc\", \"Foundation_Other\"\n",
      "\n",
      "From column \"Bsmt.Qual\" we made \"Bsmt.Qual_Gd\", \"Bsmt.Qual_TA\", \"Bsmt.Qual_Fa\", \"Bsmt.Qual_NA\"\n",
      "\n",
      "From column \"Bsmt.Cond\" we made \"Bsmt.Cond_TA\", \"Bsmt.Cond_Fa\", \"Bsmt.Cond_NA\"\n",
      "\n",
      "From column \"Bsmt.Exposure\" we made \"Bsmt.Exposure_Av\", \"Bsmt.Exposure_Mn\", \"Bsmt.Exposure_No\", \"Bsmt.Exposure_NA\"\n",
      "\n",
      "From column \"BsmtFin.Type.1\" we made \"BsmtFin.Type.1_ALQ\", \"BsmtFin.Type.1_BLQ\", \"BsmtFin.Type.1_Rec\", \"BsmtFin.Type.1_LwQ\", \"BsmtFin.Type.1_Unf\", \"BsmtFin.Type.1_NA\"\n",
      "\n",
      "From column \"BsmtFin.Type.2\" we made \"BsmtFin.Type.2_ALQ\", \"BsmtFin.Type.2_BLQ\", \"BsmtFin.Type.2_Rec\", \"BsmtFin.Type.2_LwQ\", \"BsmtFin.Type.2_Unf\", \"BsmtFin.Type.2_NA\"\n",
      "\n",
      "From column \"Central.Air\" we made \"Central.Air_Y\"\n",
      "\n",
      "From column \"Garage.Type\" we made \"Garage.Type_Attchd\", \"Garage.Type_Basment\", \"Garage.Type_BuiltIn\", \"Garage.Type_CarPort\", \"Garage.Type_Detchd\", \"Garage.Type_NoGarage\"\n",
      "\n",
      "From column \"Garage.Finish\" we made \"Garage.Finish_RFn\", \"Garage.Finish_Unf\", \"Garage.Finish_NoGarage\"\n",
      "\n",
      "From column \"Sale.Type\" we made \"Sale.Type_GroupedWD\", \"Sale.Type_Other\"\n",
      "\n",
      "From column \"Sale.Condition\" we made \"Sale.Condition_AdjLand\", \"Sale.Condition_Alloca\", \"Sale.Condition_Family\", \"Sale.Condition_Normal\", \"Sale.Condition_Partial\"\n",
      "\n",
      "From column \"Condition\" we made \"Condition_Railroad\", \"Condition_Roads\", \"Condition_Positive\", \"Condition_RoadsAndRailroad\"\n",
      "\n",
      "From column \"Exterior\" we made \"Exterior_BrkFace\", \"Exterior_CemntBd\", \"Exterior_HdBoard\", \"Exterior_MetalSd\", \"Exterior_Plywood\", \"Exterior_Stucco\", \"Exterior_VinylSd\", \"Exterior_Wd Sdng\", \"Exterior_WdShing\", \"Exterior_Other\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cat in categorical_columns:\n",
    "    dummies = []\n",
    "    for col in model_data.columns:\n",
    "        if col.startswith(cat + \"_\"):\n",
    "            dummies.append(f'\"{col}\"')\n",
    "    dummies_str = ', '.join(dummies)\n",
    "    print(f'From column \"{cat}\" we made {dummies_str}\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test splitting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data will now be organized as follows:\n",
    "\n",
    "- The features form a matrix $X$ of size $m \\times n$, where $m$ is the number of data items, and $n$ is the number of features.\n",
    "- The target forms a column-matrix $y$ of length $m$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data.drop(columns=['SalePrice']).copy()\n",
    "y = model_data['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      Lot.Frontage  Lot.Area  Lot.Shape  Land.Slope  Overall.Qual  \\\n",
       " 0            141.0   31770.0          1           0             5   \n",
       " 1             80.0   11622.0          0           0             4   \n",
       " 2             81.0   14267.0          1           0             5   \n",
       " 3             93.0   11160.0          0           0             6   \n",
       " 4             74.0   13830.0          1           0             4   \n",
       " ...            ...       ...        ...         ...           ...   \n",
       " 2925          37.0    7937.0          1           0             5   \n",
       " 2926          68.0    8885.0          1           1             4   \n",
       " 2927          62.0   10441.0          0           0             4   \n",
       " 2928          77.0   10010.0          0           1             4   \n",
       " 2929          74.0    9627.0          0           1             6   \n",
       " \n",
       "       Overall.Cond  Mas.Vnr.Area  Exter.Qual  Exter.Cond  BsmtFin.SF.1  ...  \\\n",
       " 0                4         112.0           2           2         639.0  ...   \n",
       " 1                5           0.0           2           2         468.0  ...   \n",
       " 2                5         108.0           2           2         923.0  ...   \n",
       " 3                4           0.0           1           2        1065.0  ...   \n",
       " 4                4           0.0           2           2         791.0  ...   \n",
       " ...            ...           ...         ...         ...           ...  ...   \n",
       " 2925             5           0.0           2           2         819.0  ...   \n",
       " 2926             4           0.0           2           2         301.0  ...   \n",
       " 2927             4           0.0           2           2         337.0  ...   \n",
       " 2928             4           0.0           2           2        1071.0  ...   \n",
       " 2929             4          94.0           2           2         758.0  ...   \n",
       " \n",
       "       Exterior_BrkFace  Exterior_CemntBd  Exterior_HdBoard  Exterior_MetalSd  \\\n",
       " 0                 True             False             False             False   \n",
       " 1                False             False             False             False   \n",
       " 2                False             False             False             False   \n",
       " 3                 True             False             False             False   \n",
       " 4                False             False             False             False   \n",
       " ...                ...               ...               ...               ...   \n",
       " 2925             False             False              True             False   \n",
       " 2926             False             False              True             False   \n",
       " 2927             False             False              True             False   \n",
       " 2928             False             False              True             False   \n",
       " 2929             False             False              True             False   \n",
       " \n",
       "       Exterior_Plywood  Exterior_Stucco  Exterior_VinylSd  Exterior_Wd Sdng  \\\n",
       " 0                False            False             False             False   \n",
       " 1                False            False              True             False   \n",
       " 2                False            False             False              True   \n",
       " 3                False            False             False             False   \n",
       " 4                False            False              True             False   \n",
       " ...                ...              ...               ...               ...   \n",
       " 2925             False            False             False             False   \n",
       " 2926             False            False             False             False   \n",
       " 2927             False            False             False             False   \n",
       " 2928             False            False             False             False   \n",
       " 2929             False            False             False             False   \n",
       " \n",
       "       Exterior_WdShing  Exterior_Other  \n",
       " 0                False           False  \n",
       " 1                False           False  \n",
       " 2                False           False  \n",
       " 3                False           False  \n",
       " 4                False           False  \n",
       " ...                ...             ...  \n",
       " 2925             False           False  \n",
       " 2926             False           False  \n",
       " 2927             False           False  \n",
       " 2928             False           False  \n",
       " 2929             False           False  \n",
       " \n",
       " [2877 rows x 164 columns],\n",
       " 0       5.332438\n",
       " 1       5.021189\n",
       " 2       5.235528\n",
       " 3       5.387390\n",
       " 4       5.278525\n",
       "           ...   \n",
       " 2925    5.153815\n",
       " 2926    5.117271\n",
       " 2927    5.120574\n",
       " 2928    5.230449\n",
       " 2929    5.274158\n",
       " Name: SalePrice, Length: 2877, dtype: float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the typical set-up of a machine learning project. Now we want to train our model *and* verify that the model provides good predictions for *unseen* data items. Why the emphasis on \"unseen\"? Because there is no use for a model that only gives predictions for the items in the data used to train it - we want our models to *generalize*.\n",
    "\n",
    "The way to assess the model's performance for unseen values is to split the dataset into two subsets: the **training** and **test** datasets.\n",
    "\n",
    "We have been using a lot of `Pandas` to manipulate our data so far. From now on we will switch to another very popular library for machine learning in Python: `Scikit-Learn`.\n",
    "\n",
    "The function `train_test_split()` will take as arguments the dataset to be split, the specification of the fraction of the dataset to be reserved for testing, and a random seed value - so that the split will always be the same whenever we run our notebook. This is a customary measure to ensure reproducibility of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42  # Any number here, really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.25,\n",
    "    random_state=RANDOM_SEED,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2877, 164), (2157, 164), (720, 164))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Xtrain.shape, Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2877,), (2157,), (720,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a linear model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start with fitting a linear model for regression. The linear model is one of the oldest and most used models for regression, due to its simplicity and strong statistical roots. A proper statistical approach to the understanding of the linear model consists of:\n",
    "\n",
    "- Understanding the statistical premises of the linear model;\n",
    "- Analyzing the features to verify that the preliminary conditions of this modeling strategy are satisfied;\n",
    "- Fitting the model;\n",
    "- Analyzing the residuals to confirm that the post-fit conditions are satisfied.\n",
    "\n",
    "Lets discuss these topics in more detail:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The statistical approach to the linear model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning we are more interested in the predictive capability of a model, rather than its inductive use to analyze the relation between features and target (or independent and dependent variables, in the statistical terminology). But even to a machine learning practitioner, understanding the statistical basis of the linear model may lead to better predictive performance. For instance:\n",
    "\n",
    "- Having a symmetrical residual is usually associated with better mean-squared-error (MSE) than having a long-tailed assymmetric residual;\n",
    "- Non-significant parameters (in a hypothesis-testing sense) may indicate superfluous variables in the model, which could be associated with reduced performance in the test dataset (i.e. poor generalization).\n",
    "\n",
    "So what is the linear model in statistics? A statistical model is a way to describe probabilistically the relation between features and targets, usually in a parametric way.\n",
    "\n",
    "Mathematically, we are searching for a *conditional probability* density model of the form $f(Y = y | \\mathbf{x}, \\theta)$ where $\\mathbf{x}$ is the feature vector, $Y$ is the random variable associated with the target, and $\\theta$ is the vector of parameters. In plain language, we would like to describe the probability distribution of the target variable when the value of the feature vector is known and the parameters of the model are given.\n",
    "\n",
    "In the linear model, we postulate that the data $y$ is generated from the feature vector $\\mathbf{x}$ plus a random Gaussian noise of fixed standard deviation, as shown in the equation below:\n",
    "\n",
    "$$\n",
    "y = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n + \\varepsilon\n",
    "$$\n",
    "\n",
    "where $\\varepsilon \\sim N(0, \\sigma)$\n",
    "\n",
    "The addition of the noise term causes the $y$ value to become a random variable itself, thus making the probabilistic model mentioned above. For a given value of $\\mathbf{x}$, the value of $y$ is obtained by adding the constant value $\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n$ to a normal random variable $\\varepsilon$. Remember that, for normal random variables, adding a constant keeps the variable normal, with a shifted mean-value parameter. Therefore:\n",
    "\n",
    "$$\n",
    "Y \\sim N(\\mu = (\\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n), \\sigma)\n",
    "$$\n",
    "\n",
    "Lets write\n",
    "\n",
    "$$\n",
    "\\hat{y} = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2 + \\cdots + \\theta_n x_n\n",
    "$$\n",
    "\n",
    "for simplicity, then the model above is rewritten as:\n",
    "\n",
    "$$\n",
    "Y \\sim N(\\mu = \\hat{y}, \\sigma)\n",
    "$$\n",
    "\n",
    "When we have a dataset $D = \\{(\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2), \\cdots, (\\mathbf{x}_m, y_m)\\}$ of several $(\\mathbf{x}, y)$ pairs, what is their joint conditional probability density function $f(y_1, y_2, \\cdots, y_m | x_1, x_2, \\cdots, x_n, \\theta)$?\n",
    "\n",
    "We will make another supposition of the linear model: that the $(\\mathbf{x}, y)$ examples were obtained independently, and that the value of one does not impact the probability of the other. Therefore:\n",
    "\n",
    "$$\n",
    "f(y_1, y_2, \\cdots, y_m | x_1, x_2, \\cdots, x_n, \\theta) = f(y_1| x_1, \\theta) f(y_2| x_2, \\theta) \\cdots f(y_m| x_m, \\theta) \n",
    "$$\n",
    "\n",
    "Remember that the normal probability density function is as follows:\n",
    "\n",
    "$$\n",
    "Y \\sim N(\\mu, \\sigma) \\Rightarrow f(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left(-\\frac{1}{2}\\frac{(y - \\mu)^2}{\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "Thus:\n",
    "\n",
    "$$\n",
    "Y \\sim N(\\mu = \\hat{y}, \\sigma) \\Rightarrow f(y) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left(-\\frac{1}{2}\\frac{(y - \\hat{y})^2}{\\sigma^2} \\right)\n",
    "$$\n",
    "\n",
    "And the joint conditional probability density function of the entire dataset becomes:\n",
    "\n",
    "\n",
    "$$\n",
    "f(y_1, y_2, \\cdots, y_m | x_1, x_2, \\cdots, x_n, \\theta) = \\prod_{i=1}^{m} \\left(\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left(-\\frac{1}{2}\\frac{(y_i - \\hat{y_i})^2}{\\sigma^2} \\right) \\right)\n",
    "$$\n",
    "\n",
    "Expanding the product we have:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(y_1, y_2, \\cdots, y_m | x_1, x_2, \\cdots, x_n, \\theta) & = & \\prod_{i=1}^{m} \\left(\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\exp \\left(-\\frac{1}{2}\\frac{(y_i - \\hat{y_i})^2}{\\sigma^2} \\right) \\right) \\\\\n",
    "& = & \\prod_{i=1}^{m} \\left(\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\right) \\prod_{i=1}^{m} \\left( \\exp \\left(-\\frac{1}{2}\\frac{(y_i - \\hat{y_i})^2}{\\sigma^2} \\right) \\right) \\\\\n",
    "& = & \\left(\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\right)^{m} \\exp \\left(\\sum_{i=1}^{m} \\left(-\\frac{1}{2}\\frac{(y_i - \\hat{y_i})^2}{\\sigma^2} \\right) \\right) \\\\\n",
    "& = & \\left(\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\right)^{m} \\exp \\left(- \\frac{1}{2 \\sigma} \\sum_{i=1}^{m} (y_i - \\hat{y_i})^2 \\right)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "What are the \"best\" value for the parameters of the linear model? We can search for the parameters that maximize the joint conditional probability density function of the dataset. This function is called the *likelihood* of the parameters, and therefore our solution here is called a *\"maximum likelihood estimate\"* of the parameters.\n",
    "\n",
    "So we are looking for a value $\\theta^{\\star}$ of $\\theta$ to maximize $f(y_1, y_2, \\cdots, y_m | x_1, x_2, \\cdots, x_n, \\theta)$, that is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\theta^{\\star} & = & \\argmax_{\\theta} \\left\\{ f(y_1, y_2, \\cdots, y_m | x_1, x_2, \\cdots, x_n, \\theta) \\right\\}\\\\\n",
    "& = & \\argmax_{\\theta} \\left\\{ \\left(\\frac{1}{\\sigma \\sqrt{2 \\pi}} \\right)^{m} \\exp \\left(- \\frac{1}{2 \\sigma} \\sum_{i=1}^{m} (y_i - \\hat{y_i})^2 \\right) \\right\\} \\\\\n",
    "& = & \\argmax_{\\theta} \\left\\{ \\exp \\left(- \\frac{1}{2 \\sigma} \\sum_{i=1}^{m} (y_i - \\hat{y_i})^2 \\right) \\right\\} \\\\\n",
    "& = & \\argmax_{\\theta} \\left\\{ - \\frac{1}{2 \\sigma} \\sum_{i=1}^{m} (y_i - \\hat{y_i})^2 \\right\\} \\\\\n",
    "& = & \\argmin_{\\theta} \\left\\{ \\frac{1}{2 \\sigma} \\sum_{i=1}^{m} (y_i - \\hat{y_i})^2 \\right\\} \\\\\n",
    "& = & \\argmin_{\\theta} \\left\\{ \\sum_{i=1}^{m} (y_i - \\hat{y_i})^2 \\right\\} \\\\\n",
    "& = & \\argmin_{\\theta} \\left\\{ \\frac{1}{m} \\sum_{i=1}^{m} (y_i - \\hat{y_i})^2 \\right\\} \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Hey, look who we found! Our old friend MSE (mean-squared-error)!\n",
    "\n",
    "So, in the end, here are the lessons:\n",
    "\n",
    "- The statistical formulation of the linear model leads to the same error formulation of machine learning, which only cares for the prediction quality.\n",
    "- The statistical linear model has several assumptions:\n",
    "    - The samples are independent;\n",
    "    - The target is *truly* generated from the linear predictive formula plus a normally-distributed error;\n",
    "    - The error has zero mean and constant standard deviation (the *homoscedasticity* hypothesis);\n",
    "    - There is no error in the feature measurement. That is, $\\mathbf{x}_{i}$ are constants, not random variables. All the error is in the target;\n",
    "- If the assumptions of the linear model are satisfied, you can analyze the parameters with greater sophistication (the machine learning formulation does not bring this finesse). For instance, you can run hypothesis tests on the values of the parameters to determine whether they refute the null hypothesis $\\theta_i = 0$ with a given statistical significance level. Which, in plain language, means that you don't really trust that the associated feature impacts the target, or if it is just an accident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06112775876101971"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 15.11%\n"
     ]
    }
   ],
   "source": [
    "error_percent = 100 * (10**RMSE - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is a crucial and transformative step in the process of preparing data for machine learning. It involves creating, modifying, and selecting relevant features from the raw dataset to improve a model's performance. Two essential techniques in feature engineering are ````StandardScaler```` and ````PolynomialFeatures````\n",
    "\n",
    "````StandardScaler```` plays a vital role in feature engineering by ensuring that all features have the same scale. This process is essential because different features may have different units or scales, and many machine learning algorithms are sensitive to these variations. StandardScaler standardizes the data, giving it a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "````PolynomialFeatures```` is another valuable tool in feature engineering. It helps capture nonlinear relationships between features by generating new features based on combinations of the original ones. For instance, if you have a feature 'x,' creating its squared term 'x^2' allows the model to account for quadratic relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lot.Frontage',\n",
       " 'Lot.Area',\n",
       " 'Lot.Shape',\n",
       " 'Land.Slope',\n",
       " 'Overall.Qual',\n",
       " 'Overall.Cond',\n",
       " 'Mas.Vnr.Area',\n",
       " 'Exter.Qual',\n",
       " 'Exter.Cond',\n",
       " 'BsmtFin.SF.1',\n",
       " 'BsmtFin.SF.2',\n",
       " 'Bsmt.Unf.SF',\n",
       " 'Total.Bsmt.SF',\n",
       " 'Heating.QC',\n",
       " 'Electrical',\n",
       " 'X1st.Flr.SF',\n",
       " 'X2nd.Flr.SF',\n",
       " 'Low.Qual.Fin.SF',\n",
       " 'Gr.Liv.Area',\n",
       " 'Bsmt.Full.Bath',\n",
       " 'Bsmt.Half.Bath',\n",
       " 'Full.Bath',\n",
       " 'Half.Bath',\n",
       " 'Bedroom.AbvGr',\n",
       " 'Kitchen.AbvGr',\n",
       " 'Kitchen.Qual',\n",
       " 'TotRms.AbvGrd',\n",
       " 'Functional',\n",
       " 'Fireplaces',\n",
       " 'Garage.Cars',\n",
       " 'Garage.Area',\n",
       " 'Paved.Drive',\n",
       " 'Wood.Deck.SF',\n",
       " 'Open.Porch.SF',\n",
       " 'Enclosed.Porch',\n",
       " 'X3Ssn.Porch',\n",
       " 'Screen.Porch',\n",
       " 'Pool.Area',\n",
       " 'Fence',\n",
       " 'Misc.Val',\n",
       " 'Mo.Sold',\n",
       " 'Yr.Sold',\n",
       " 'Garage.Age',\n",
       " 'Remod.Age',\n",
       " 'House.Age']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numColumns = list(Xtrain.select_dtypes('number').columns)\n",
    "numColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "pipe = ColumnTransformer([\n",
    "    ('pipe', Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ]), numColumns),\n",
    "], remainder='passthrough')\n",
    "\n",
    "Xtrain_proc = pipe.fit_transform(Xtrain)\n",
    "Xtest_proc = pipe.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso model, short for \"Least Absolute Shrinkage and Selection Operator,\" is a linear regression technique used in machine learning and statistics. It is a variation of linear regression that includes L1 regularization.\n",
    "\n",
    "L1 regularization adds a penalty term to the standard linear regression loss function. This penalty is the absolute sum of the coefficients of the features (the weights assigned to each feature), multiplied by a hyperparameter called 'alpha'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.01)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0.01)\n",
    "\n",
    "model.fit(Xtrain_proc, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00276147,  0.        ,  0.        , ..., -0.        ,\n",
       "       -0.        , -0.        ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = model.predict(Xtest_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07113914278977039"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 17.80%\n"
     ]
    }
   ],
   "source": [
    "error_percent = 100 * (10**RMSE - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 17.80% average error suggests that the model may benefit from improvement.To perform a hyperparameter grid search and compare different hyperparameters for the Lasso model, we can use the GridSearchCV class from scikit-learn. This class allows us to search for the best hyperparameters by evaluating models with different parameter values and performing cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso using Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.01, 0.1, 1.0, 10.0]}, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={&#x27;alpha&#x27;: [0.001, 0.01, 0.1, 1.0, 10.0]}, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(), n_jobs=-1,\n",
       "             param_grid={'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]}, verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    Lasso(),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(Xtrain_proc, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter found: {'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Get the best hyperparameters and best model\n",
    "best_alpha = grid.best_params_['alpha']\n",
    "best_model = grid.best_estimator_\n",
    "lasso_coefficients = best_model.coef_\n",
    "\n",
    "print(\"Best hyperparameter found:\", grid.best_params_)\n",
    "\n",
    "ypred = best_model.predict(Xtest_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052877467933635826"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(ytest, ypred))\n",
    "\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 12.95%\n"
     ]
    }
   ],
   "source": [
    "error_percent = 100 * (10**RMSE - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By applying grid search with cross-validation (cv = 5), the Lasso model achieved significantly better performance with a reduced average error of 12.95%. This demonstrates the importance of tuning model hyperparameters, in this case, 'alpha,' to enhance prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest is a commonly-used machine learning algorithm, which combines the output of multiple decision trees to reach a single result. Its ease of use and flexibility have fueled its adoption, as it handles both classification and regression problems.\n",
    "\n",
    "To perform a hyperparameter grid search with a Random Forest model, we can use a similar approach to the one used for the Lasso model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter found: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "Best model: RandomForestRegressor(n_estimators=1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 100, 1000],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    RandomForestRegressor(),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "grid.fit(Xtrain, ytrain)\n",
    "\n",
    "# Get the best hyperparameters and best model\n",
    "best_n_estimators = grid.best_params_['n_estimators']\n",
    "best_model = grid.best_estimator_\n",
    "\n",
    "print(\"Best hyperparameter found:\", grid.best_params_)\n",
    "print(\"Best model:\", best_model)\n",
    "\n",
    "ypred = best_model.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06228236698298739"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE = np.sqrt(mean_squared_error(ytest, ypred))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 15.42%\n"
     ]
    }
   ],
   "source": [
    "error_percent = 100 * (10**RMSE - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Trees Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameters we've found as the best for Random Forest are typically a good choice for the Extra Trees Regressor as well. Both models share many characteristics, and key hyperparameters such as the maximum tree depth ('max_depth'), the number of estimators ('n_estimators'), and the splitting criterion ('min_samples_split') serve similar functions in both models. Then, we can apply the same hyperparameters to the Extra Trees Regressor  to utilize these optimized settings for this type of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058522687630717586"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "model = ExtraTreesRegressor(n_estimators=1000, n_jobs=-1, random_state=RANDOM_SEED, max_depth=None, min_samples_split=2)\n",
    "\n",
    "model.fit(Xtrain, ytrain)\n",
    "ypred = model.predict(Xtest)\n",
    "\n",
    "RMSE = np.sqrt(mean_squared_error(ytest, ypred))\n",
    "\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error is 14.43%\n"
     ]
    }
   ],
   "source": [
    "error_percent = 100 * (10**RMSE - 1)\n",
    "print(f'Average error is {error_percent:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Random Forest and Extra Trees Regressor had similar average errors, but Extra Trees Regressor performed slightly better. These models are ensembles of decision trees. However, Random Forest uses bootstrapping and feature selection, while Extra Trees Regressor employs random feature selection and does not bootstrap. In this case, Extra Trees Regressor's randomization might have been more beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing the most significant features for predicting house sale prices is a viable option. In this scenario, we will focus on assessing the key features employed in the Lasso Model, as it exhibited the lowest average error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Associate the coefficients with the corresponding columns of the dataset\n",
    "feature_names = Xtrain.columns  \n",
    "\n",
    "# Create a dictionary that maps column names to coefficients\n",
    "feature_coefficients = dict(zip(feature_names, lasso_coefficients))\n",
    "\n",
    "# Sort the features by the absolute value of their coefficients in descending order\n",
    "sorted_feature_coefficients = sorted(feature_coefficients.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "# Plot most important features\n",
    "top_features = 10  # Defina o nmero de principais features que deseja visualizar\n",
    "top_feature_names = [feature[0] for feature in sorted_feature_coefficients[:top_features]]\n",
    "top_feature_coefficients = [feature[1] for feature in sorted_feature_coefficients[:top_features]]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_feature_names, top_feature_coefficients)\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Feature Name\")\n",
    "plt.title(\"Top {} Features in Lasso Model\".format(top_features))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Lasso model with Grid Search significantly outperforms the basic Lasso model. The average error decreased from 17.80% to 12.95%, showing that hyperparameter tuning improved the model's predictive accuracy.\n",
    "\n",
    "While the Lasso model with Grid Search outperformed also the tree-based models, it's crucial to recognize that the choice of model can depend on the specific dataset. Random Forest and Extra Trees Regressor are capable of capturing complex relationships in data, and their performance can be enhanced further by tuning hyperparameters or exploring different feature engineering techniques.\n",
    "\n",
    "Finally, the analysis of feature importance revealed that 'Gr. Liv. Area' emerged as the most influential feature in our predictive model, boasting the highest coefficient value. On the other hand, 'Garage Age' and 'Has Alley' exhibited relatively lower negative coefficient values, suggesting their limited impact on the house sale price prediction.\n",
    "\n",
    "For future steps, we must decide whether to retain, further transform, or eliminate features with negative coefficients and try to create a second version of feature engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ames",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbd4e51fa3f3bf2a2317a230e3ac8d5fc66f1a44e44c3383f6bf669b9d199507"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
